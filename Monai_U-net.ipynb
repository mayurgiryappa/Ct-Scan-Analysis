{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35efea7c-9d16-436e-a191-e9373627a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monai.networks.nets import UNet \n",
    "from monai.networks.layers import Norm # For specifying normalization layers in UNet\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71324849-3971-4d08-a421-994edc216a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(opt):\n",
    "    \"\"\"\n",
    "    Generates a 3D segmentation model (e.g., UNet from MONAI) based on options,\n",
    "    handles GPU placement, and loads pre-trained weights if specified.\n",
    "\n",
    "    Args:\n",
    "        opt: An object or dictionary containing configuration options like:\n",
    "            - model (str): Type of model (e.g., 'unet_resnet_style' or just 'unet').\n",
    "            - model_depth (int): Can be used to select UNet configurations if desired,\n",
    "                                 or ignored if using a fixed UNet architecture.\n",
    "            - input_W, input_H, input_D (int): Input dimensions (used for MONAI UNet).\n",
    "            - n_seg_classes (int): Number of segmentation classes.\n",
    "            - no_cuda (bool): If True, use CPU; otherwise, use GPU.\n",
    "            - gpu_id (list of int): List of GPU IDs to use.\n",
    "            - phase (str): Current phase ('train', 'test', etc.).\n",
    "            - pretrain_path (str, optional): Path to pre-trained model weights.\n",
    "            - new_layer_names (list of str, optional): Names of new layers for fine-tuning.\n",
    "            - freeze_base (bool, optional): If True, freeze base parameters during fine-tuning.\n",
    "    Returns:\n",
    "        torch.nn.Module: The generated (and potentially pre-trained) model.\n",
    "        dict or torch.nn.Parameter: Parameters for the optimizer.\n",
    "    \"\"\"\n",
    "    print(\"--- Entering generate_model ---\")\n",
    "    print(f\"Options received: {opt}\")\n",
    "\n",
    "    # For 3D segmentation, U-Net is a common choice.\n",
    "    # The original code structure was trying to build a ResNet.\n",
    "    # MONAI's UNet can have ResNet-like blocks, or you can use other 3D architectures.\n",
    "    # We'll use a MONAI UNet here as an example.\n",
    "    # The 'opt.model' and 'opt.model_depth' might need to be re-interpreted\n",
    "    # for selecting different UNet configurations if you have them.\n",
    "\n",
    "    assert opt.model in ['resnet', 'unet'], \\\n",
    "        f\"Unsupported model type: {opt.model}. Expected 'resnet' (interpreted as UNet-style for 3D) or 'unet'.\"\n",
    "\n",
    "    model = None\n",
    "\n",
    "    # Example: Using MONAI UNet.\n",
    "    # You might want to map opt.model_depth to different UNet channel configurations\n",
    "    # or numbers of residual units if you want to keep that parameter meaningful.\n",
    "    # For simplicity, this example uses a fixed UNet configuration.\n",
    "    # The parameters like 'sample_input_W/H/D' are not directly used by MONAI UNet constructor\n",
    "    # but are good for defining `roi_size` or `patch_size` in data loading/training.\n",
    "    # `num_seg_classes` is equivalent to `out_channels`.\n",
    "    \n",
    "    # Assuming 'resnet' in opt.model implies a UNet-style architecture for 3D segmentation\n",
    "    if opt.model == 'resnet' or opt.model == 'unet':\n",
    "        print(f\"Creating MONAI UNet for 3D segmentation with {opt.n_seg_classes} output classes.\")\n",
    "        # Example UNet configuration - you'll likely want to customize this\n",
    "        # based on opt.model_depth or other specific needs.\n",
    "        unet_channels = (16, 32, 64, 128, 256) # Default, can be adjusted\n",
    "        unet_strides = (2, 2, 2, 2)\n",
    "        num_res_units = 2 # ResNet-like blocks\n",
    "\n",
    "        if hasattr(opt, 'model_depth'): # Optionally use model_depth to vary UNet\n",
    "            if opt.model_depth <= 18:\n",
    "                unet_channels = (16, 32, 64, 128)\n",
    "                unet_strides = (2, 2, 2)\n",
    "            elif opt.model_depth <= 34:\n",
    "                unet_channels = (16, 32, 64, 128, 256)\n",
    "                unet_strides = (2, 2, 2, 2)\n",
    "            # Add more conditions for deeper/larger UNets if needed\n",
    "\n",
    "        try:\n",
    "            model = UNet(\n",
    "                spatial_dims=3,\n",
    "                in_channels=1,  # Assuming 1 input channel for CT scans (e.g., opt.input_channels)\n",
    "                out_channels=opt.n_seg_classes,\n",
    "                channels=unet_channels,\n",
    "                strides=unet_strides,\n",
    "                num_res_units=num_res_units,\n",
    "                norm=Norm.BATCH # Or Norm.INSTANCE, etc.\n",
    "            )\n",
    "            print(f\"MONAI UNet model instantiated: {type(model)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error instantiating MONAI UNet: {e}\")\n",
    "            raise e # Re-raise the exception to stop execution if model creation fails\n",
    "\n",
    "    if model is None:\n",
    "        raise ValueError(\"Model could not be instantiated. Check model type and parameters in 'opt'.\")\n",
    "\n",
    "    parameters_for_optimizer = model.parameters()  # Default\n",
    "\n",
    "    # --- Load Pretrained Weights (before moving to GPU and DataParallel for simplicity) ---\n",
    "    if hasattr(opt, 'phase') and opt.phase != 'test' and \\\n",
    "       hasattr(opt, 'pretrain_path') and opt.pretrain_path:\n",
    "        print(f'Loading pretrained model from: {opt.pretrain_path}')\n",
    "        try:\n",
    "            pretrain = torch.load(opt.pretrain_path, map_location='cpu')\n",
    "            current_model_dict = model.state_dict()\n",
    "            \n",
    "            pretrained_state_dict_source = pretrain['state_dict'] if isinstance(pretrain, dict) and 'state_dict' in pretrain else pretrain\n",
    "            \n",
    "            filtered_pretrained_dict = {}\n",
    "            loaded_keys_count = 0\n",
    "            skipped_keys = []\n",
    "\n",
    "            for k, v_pretrain in pretrained_state_dict_source.items():\n",
    "                original_key_pretrain = k\n",
    "                if k.startswith('module.'): # If pretrain was saved from a DataParallel model\n",
    "                    k = k[7:]\n",
    "                \n",
    "                if k in current_model_dict:\n",
    "                    v_model = current_model_dict[k]\n",
    "                    if v_model.shape == v_pretrain.shape:\n",
    "                        filtered_pretrained_dict[k] = v_pretrain\n",
    "                        loaded_keys_count += 1\n",
    "                    else:\n",
    "                        skipped_keys.append(\n",
    "                            f\"'{original_key_pretrain}' (shape mismatch: model {v_model.shape}, pretrain {v_pretrain.shape})\"\n",
    "                        )\n",
    "                else:\n",
    "                    skipped_keys.append(f\"'{original_key_pretrain}' (not in current model)\")\n",
    "\n",
    "            if loaded_keys_count > 0:\n",
    "                current_model_dict.update(filtered_pretrained_dict)\n",
    "                model.load_state_dict(current_model_dict)\n",
    "                print(f\"Successfully loaded {loaded_keys_count} matching layers from pretrained model.\")\n",
    "            else:\n",
    "                print(\"Warning: No layers were loaded from the pretrained model. Check keys and model architecture.\")\n",
    "            if skipped_keys:\n",
    "                print(f\"Skipped {len(skipped_keys)} pretrained layers due to name or shape mismatch: {', '.join(skipped_keys[:5])}{'...' if len(skipped_keys) > 5 else ''}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Pretrained model file not found at {opt.pretrain_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pretrained model: {e}\")\n",
    "\n",
    "\n",
    "        # --- Prepare parameter groups for fine-tuning ---\n",
    "        new_parameters_list = []\n",
    "        base_parameters_list = list(model.parameters()) # Default to all parameters being base\n",
    "\n",
    "        if hasattr(opt, 'new_layer_names') and opt.new_layer_names:\n",
    "            for param_name, param_obj in model.named_parameters():\n",
    "                for new_layer_identifier in opt.new_layer_names:\n",
    "                    if new_layer_identifier in param_name:\n",
    "                        new_parameters_list.append(param_obj)\n",
    "                        # Ensure requires_grad is True for new parameters\n",
    "                        param_obj.requires_grad = True \n",
    "                        break \n",
    "\n",
    "            if new_parameters_list:\n",
    "                new_param_ids = set(map(id, new_parameters_list))\n",
    "                base_parameters_list = [p for p in model.parameters() if id(p) not in new_param_ids]\n",
    "                print(f\"Identified {len(new_parameters_list)} new parameters and {len(base_parameters_list)} base parameters for fine-tuning.\")\n",
    "            else:\n",
    "                print(\"Warning: 'new_layer_names' provided, but no matching parameters found. All parameters treated as base.\")\n",
    "        else:\n",
    "            print(\"No 'new_layer_names' specified for fine-tuning. All parameters treated as base.\")\n",
    "        \n",
    "        parameters_for_optimizer = {\n",
    "            'base_parameters': base_parameters_list,\n",
    "            'new_parameters': new_parameters_list  # Will be empty if none found/specified\n",
    "        }\n",
    "\n",
    "        if hasattr(opt, 'freeze_base') and opt.freeze_base and base_parameters_list:\n",
    "            print(\"Freezing base parameters.\")\n",
    "            for param in base_parameters_list:\n",
    "                param.requires_grad = False\n",
    "        elif base_parameters_list: # Ensure base parameters are trainable if not frozen\n",
    "             for param in base_parameters_list:\n",
    "                param.requires_grad = True\n",
    "\n",
    "    # --- GPU / CPU Handling ---\n",
    "    if not opt.no_cuda and torch.cuda.is_available():\n",
    "        if hasattr(opt, 'gpu_id') and opt.gpu_id and len(opt.gpu_id) > 0:\n",
    "            if len(opt.gpu_id) > 1:\n",
    "                print(f\"Using nn.DataParallel for GPUs: {opt.gpu_id}\")\n",
    "                model = nn.DataParallel(model, device_ids=opt.gpu_id)\n",
    "                # The model (and its parameters) will be on opt.gpu_id[0]\n",
    "                # DataParallel handles distributing data during forward pass\n",
    "                model.cuda(opt.gpu_id[0]) \n",
    "            else: \n",
    "                device_id = opt.gpu_id[0]\n",
    "                device = torch.device(f\"cuda:{device_id}\")\n",
    "                model = model.to(device)\n",
    "                print(f\"Model moved to GPU: cuda:{device_id}\")\n",
    "        else: \n",
    "            device = torch.device(\"cuda\") # Defaults to cuda:0\n",
    "            model = model.to(device)\n",
    "            print(\"Model moved to default GPU (cuda:0 or primary CUDA device).\")\n",
    "    else:\n",
    "        if opt.no_cuda:\n",
    "            print(\"CUDA disabled by user (opt.no_cuda=True). Using CPU.\")\n",
    "        else:\n",
    "            print(\"CUDA not available on this system. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        model = model.to(device)\n",
    "    \n",
    "    print(\"--- Exiting generate_model ---\")\n",
    "    return model, parameters_for_optimizer,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34a2978-66fd-4793-b956-129ca5be2d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA specified but not available. Switching to CPU (no_cuda=True).\n",
      "--- Entering generate_model ---\n",
      "Options received: <__main__.Options object at 0x731353114230>\n",
      "Creating MONAI UNet for 3D segmentation with 3 output classes.\n",
      "MONAI UNet model instantiated: <class 'monai.networks.nets.unet.UNet'>\n",
      "CUDA disabled by user (opt.no_cuda=True). Using CPU.\n",
      "--- Exiting generate_model ---\n",
      "An error occurred during model generation or setup: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.model = 'unet'\n",
    "        self.model_depth = 34 # Example depth\n",
    "        self.input_W = 128 # Example, not directly used by MONAI UNet constructor\n",
    "        self.input_H = 128 # Example\n",
    "        self.input_D = 128 # Example\n",
    "        self.n_seg_classes = 3 # Example: background, tumor, other structure\n",
    "        self.no_cuda = False # Set to True to force CPU\n",
    "        self.gpu_id = [0]    # Example: use GPU 0. For multi-GPU: [0, 1]\n",
    "        self.phase = 'train' # Or 'test'\n",
    "        self.pretrain_path = None # Path to your .pth or .pt file, or None\n",
    "        # self.pretrain_path = \"path/to/your/pretrained_model.pth\" \n",
    "        self.new_layer_names = [] # Example: ['model.output_conv.conv.weight'] for fine-tuning specific layers\n",
    "        # self.new_layer_names = ['final_conv'] # if your UNet has a layer with 'final_conv' in its name\n",
    "        self.freeze_base = False\n",
    "\n",
    "# Create an instance of the options\n",
    "opts = Options()\n",
    "\n",
    "# --- Special handling for GPU availability in a notebook environment ---\n",
    "# If 'no_cuda' is False, but no GPUs are actually available, override to True\n",
    "if not opts.no_cuda and not torch.cuda.is_available():\n",
    "    print(\"CUDA specified but not available. Switching to CPU (no_cuda=True).\")\n",
    "    opts.no_cuda = True\n",
    "    opts.gpu_id = [] # Clear gpu_id if forcing CPU\n",
    "\n",
    "# Generate the model\n",
    "try:\n",
    "    model, params_for_optimizer = generate_model(opts)\n",
    "    print(f\"\\nModel generated successfully: {type(model)}\")\n",
    "    if isinstance(params_for_optimizer, dict):\n",
    "        print(f\"Optimizer params: {len(params_for_optimizer.get('base_parameters', []))} base, {len(params_for_optimizer.get('new_parameters', []))} new.\")\n",
    "    else:\n",
    "        print(f\"Optimizer params: {len(list(params_for_optimizer))} total.\")\n",
    "    \n",
    "    # You can print the model structure (can be very long for UNets)\n",
    "    # print(\"\\nModel Structure:\")\n",
    "    # print(model)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model generation or setup: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf12c849-425c-436c-8716-7d82e957eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA specified but not available. Switching to CPU (no_cuda=True).\n",
      "--- Entering generate_model ---\n",
      "Options received: <__main__.Options object at 0x7313530b6870>\n",
      "Creating MONAI UNet for 3D segmentation with 3 output classes.\n",
      "MONAI UNet model instantiated: <class 'monai.networks.nets.unet.UNet'>\n",
      "CUDA disabled by user (opt.no_cuda=True). Using CPU.\n",
      "--- Exiting generate_model ---\n",
      "\n",
      "Model generated successfully: <class 'monai.networks.nets.unet.UNet'>\n",
      "Model is on device: cpu\n",
      "Optimizer params: 4809920 total trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# This is an illustrative example of how you might set up options and call the function.\n",
    "# In a real scenario, 'opt' would be populated by an argument parser or a config file.\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        # Model options\n",
    "        self.model = 'unet' \n",
    "        self.model_depth = 34 \n",
    "        self.input_channels = 1 # Number of input channels for the model\n",
    "        self.n_seg_classes = 3 # Example: background, class1, class2 (for DiceCELoss to_onehot_y=True)\n",
    "        \n",
    "        # Hardware options\n",
    "        self.no_cuda = False \n",
    "        self.gpu_id = [0]    \n",
    "        \n",
    "        # Phase and Pretraining\n",
    "        self.phase = 'train' \n",
    "        self.pretrain_path = None \n",
    "        self.new_layer_names = [] \n",
    "        self.freeze_base = False\n",
    "\n",
    "      \n",
    "        self.data_root = \"./monai/scan/label-25.nii.gz\" #callin the  with NIfTI files .nfi\n",
    "        # self.img_list_file = \"./data/train_list.txt\" \n",
    "        self.roi_size = (96, 96, 96) # Example patch size for training\n",
    "        self.batch_size = 2 # Example batch size\n",
    "        self.num_workers = 0 # For DataLoader, set to 0 for initial testing, >0 for parallel loading\n",
    "\n",
    "        # Intensity scaling/normalization ie houndsfield unit\n",
    "        self.a_min = -200.0 # HU min for scaling (e.g., for soft tissue window)\n",
    "        self.a_max = 200.0  # HU max for scaling\n",
    "        self.b_min = 0.0    # Output min after scaling\n",
    "        self.b_max = 1.0    # Output max after scaling\n",
    "        # self.norm_mean = 0.5 # For NormalizeIntensityd, if used after ScaleIntensityRanged\n",
    "        # self.norm_std = 0.5  # For NormalizeIntensityd\n",
    "\n",
    "# Create an instance of the options\n",
    "opts = Options()\n",
    "\n",
    "# --- Special handling for GPU availability in a notebook environment --- gpu requirement code\n",
    "if not opts.no_cuda and not torch.cuda.is_available():\n",
    "    print(\"CUDA specified but not available. Switching to CPU (no_cuda=True).\")\n",
    "    opts.no_cuda = True\n",
    "    opts.gpu_id = [] \n",
    "\n",
    "# Generate the model\n",
    "try:\n",
    "    # Now also expecting 'device' to be returned\n",
    "    model, params_for_optimizer, device = generate_model(opts) \n",
    "    print(f\"\\nModel generated successfully: {type(model)}\")\n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\") # Check actual device of model parameters\n",
    "    \n",
    "    if isinstance(params_for_optimizer, dict):\n",
    "        base_param_count = sum(p.numel() for p in params_for_optimizer.get('base_parameters', []) if p.requires_grad)\n",
    "        new_param_count = sum(p.numel() for p in params_for_optimizer.get('new_parameters', []) if p.requires_grad)\n",
    "        print(f\"Optimizer params: {base_param_count} trainable base params, {new_param_count} trainable new params.\")\n",
    "    else:\n",
    "        total_trainable_params = sum(p.numel() for p in params_for_optimizer if p.requires_grad)\n",
    "        print(f\"Optimizer params: {total_trainable_params} total trainable parameters.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model generation or setup: {e}\")\n",
    "    # To see the full traceback if an error occurs within generate_model\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    model = None # Ensure model is None if generation failed\n",
    "    params_for_optimizer = None\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97942f09-ee39-4b4e-bde4-04b4e50d85be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
